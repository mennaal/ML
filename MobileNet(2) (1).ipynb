{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFRllSb-Wlv0",
        "outputId": "f27b155a-172e-47df-8a4f-a4d45b28e40e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M5hQk0VWlml",
        "outputId": "1295468d-95ce-441e-d971-b61bddc3eda5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Alzheimer_s\\ Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiFkrwPrWqUs",
        "outputId": "3186bc95-d92a-44d2-9262-4a58cc649dcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Alzheimer_s Dataset.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#try 1 train part\n",
        "#( 10 epochs ,test accuracy : 0.67)"
      ],
      "metadata": {
        "id": "oqxtUp3eK9Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TjEySGmWQNl",
        "outputId": "17bd5045-af47-448d-8d02-b55c617b01aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 images belonging to 4 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "171/171 [==============================] - 1036s 6s/step - loss: 0.9061 - accuracy: 0.6112\n",
            "Epoch 2/10\n",
            "171/171 [==============================] - 997s 6s/step - loss: 0.6217 - accuracy: 0.7329\n",
            "Epoch 3/10\n",
            "171/171 [==============================] - 991s 6s/step - loss: 0.4873 - accuracy: 0.7952\n",
            "Epoch 4/10\n",
            "171/171 [==============================] - 989s 6s/step - loss: 0.3861 - accuracy: 0.8481\n",
            "Epoch 5/10\n",
            "171/171 [==============================] - 991s 6s/step - loss: 0.3172 - accuracy: 0.8774\n",
            "Epoch 6/10\n",
            "171/171 [==============================] - 991s 6s/step - loss: 0.2764 - accuracy: 0.8922\n",
            "Epoch 7/10\n",
            "171/171 [==============================] - 993s 6s/step - loss: 0.2147 - accuracy: 0.9184\n",
            "Epoch 8/10\n",
            "171/171 [==============================] - 999s 6s/step - loss: 0.2051 - accuracy: 0.9242\n",
            "Epoch 9/10\n",
            "171/171 [==============================] - 999s 6s/step - loss: 0.1654 - accuracy: 0.9367\n",
            "Epoch 10/10\n",
            "171/171 [==============================] - 1000s 6s/step - loss: 0.1372 - accuracy: 0.9483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "# Define the path to the ZIP file\n",
        "zip_file_path = \"/content/drive/MyDrive/Alzheimer_s Dataset.zip\"\n",
        "\n",
        "extracted_dir = \"/content/Alzheimer_s_Dataset\"  # Define the directory where files will be extracted\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Get the path to the inner directory containing the dataset files\n",
        "inner_dir = os.path.join(extracted_dir, 'Alzheimer_s Dataset')\n",
        "\n",
        "# Define paths to train data directory\n",
        "train_dir = os.path.join(inner_dir, 'train')\n",
        "\n",
        "# Check if the train directory exists\n",
        "if not os.path.exists(train_dir):\n",
        "    print(\"Train directory not found:\", train_dir)\n",
        "    exit()\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 30\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Load and augment training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'  # Assuming images are organized in folders by class\n",
        ")\n",
        "\n",
        "# Load MobileNet model without top (classification) layer\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom classification layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"trained_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#try 1 test part (test accuracy : 0.67)"
      ],
      "metadata": {
        "id": "yUCroRfzLO-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to test data directory\n",
        "test_dir = os.path.join(inner_dir, 'test')\n",
        "\n",
        "# Check if the test directory exists\n",
        "if not os.path.exists(test_dir):\n",
        "    print(\"Test directory not found:\", test_dir)\n",
        "    exit()\n",
        "\n",
        "# Load test data (no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assuming images are organized in folders by class\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predict labels for test data\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulO0JtGdIt-O",
        "outputId": "3e941d10-1ced-4483-d65e-9dfaf36f4b71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1279 images belonging to 4 classes.\n",
            "43/43 [==============================] - 59s 1s/step - loss: 2.0263 - accuracy: 0.6701\n",
            "Test Accuracy: 0.6700547337532043\n",
            "43/43 [==============================] - 50s 1s/step\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    MildDemented       1.00      0.01      0.02       179\n",
            "ModerateDemented       0.00      0.00      0.00        12\n",
            "     NonDemented       0.63      0.96      0.76       640\n",
            "VeryMildDemented       0.80      0.54      0.64       448\n",
            "\n",
            "        accuracy                           0.67      1279\n",
            "       macro avg       0.61      0.38      0.36      1279\n",
            "    weighted avg       0.73      0.67      0.61      1279\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvynZSu4JQ8w",
        "outputId": "b23213ab-d547-49c4-a5ea-c0f4d8f904e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model_1.h5')"
      ],
      "metadata": {
        "id": "OlLC23BVJTQ7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jG4igBV60F_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuMDwDUe0F1X",
        "outputId": "d573abca-4b31-4ada-cb43-7b92ab2c8bfd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Path to your model\n",
        "model_path = '/content/drive/MyDrive/model_1.h5'\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "5eRqjIP80FvJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jRWV5BH0hV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2 train part\n",
        "#( 50 epochs ,test accuracy : 0.69)"
      ],
      "metadata": {
        "id": "breYMcT9zymh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the path to the ZIP file\n",
        "zip_file_path = \"/content/drive/MyDrive/Alzheimer_s Dataset.zip\"\n",
        "\n",
        "extracted_dir = \"/content/Alzheimer_s_Dataset\"  # Define the directory where files will be extracted\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Get the path to the inner directory containing the dataset files\n",
        "inner_dir = os.path.join(extracted_dir, 'Alzheimer_s Dataset')\n",
        "\n",
        "# Define paths to train data directory\n",
        "train_dir = os.path.join(inner_dir, 'train')\n",
        "\n",
        "# Check if the train directory exists\n",
        "if not os.path.exists(train_dir):\n",
        "    print(\"Train directory not found:\", train_dir)\n",
        "    exit()\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 30\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,  # Additional rotation\n",
        "    width_shift_range=0.2,  # Additional horizontal shift\n",
        "    height_shift_range=0.2,  # Additional vertical shift\n",
        "    fill_mode='nearest'  # Fill in missing pixels with the nearest available value\n",
        ")\n",
        "\n",
        "# Load and augment training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'  # Assuming images are organized in folders by class\n",
        ")\n",
        "\n",
        "# Load MobileNet model without top (classification) layer\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom classification layers with regularization\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "    Dense(512, activation='relu'),  # Reduced number of neurons\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "    Dense(256, activation='relu'),  # Further reduced number of neurons\n",
        "    BatchNormalization(),  # Batch normalization layer\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=50, callbacks=[early_stopping])\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"trained_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbxKR8ERzz1J",
        "outputId": "33e7f100-94f4-4ead-f3d2-6768abd13156"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 images belonging to 4 classes.\n",
            "Epoch 1/50\n",
            "171/171 [==============================] - 89s 384ms/step - loss: 1.0234 - accuracy: 0.5667\n",
            "Epoch 2/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.7440 - accuracy: 0.6639\n",
            "Epoch 3/50\n",
            "171/171 [==============================] - 67s 391ms/step - loss: 0.6403 - accuracy: 0.7237\n",
            "Epoch 4/50\n",
            "171/171 [==============================] - 67s 391ms/step - loss: 0.5294 - accuracy: 0.7838\n",
            "Epoch 5/50\n",
            "171/171 [==============================] - 67s 388ms/step - loss: 0.4652 - accuracy: 0.8133\n",
            "Epoch 6/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.3689 - accuracy: 0.8535\n",
            "Epoch 7/50\n",
            "171/171 [==============================] - 69s 401ms/step - loss: 0.3348 - accuracy: 0.8723\n",
            "Epoch 8/50\n",
            "171/171 [==============================] - 66s 384ms/step - loss: 0.2965 - accuracy: 0.8901\n",
            "Epoch 9/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.2621 - accuracy: 0.9043\n",
            "Epoch 10/50\n",
            "171/171 [==============================] - 67s 394ms/step - loss: 0.2318 - accuracy: 0.9156\n",
            "Epoch 11/50\n",
            "171/171 [==============================] - 68s 397ms/step - loss: 0.2224 - accuracy: 0.9217\n",
            "Epoch 12/50\n",
            "171/171 [==============================] - 66s 386ms/step - loss: 0.1877 - accuracy: 0.9354\n",
            "Epoch 13/50\n",
            "171/171 [==============================] - 68s 395ms/step - loss: 0.1725 - accuracy: 0.9399\n",
            "Epoch 14/50\n",
            "171/171 [==============================] - 68s 397ms/step - loss: 0.1648 - accuracy: 0.9449\n",
            "Epoch 15/50\n",
            "171/171 [==============================] - 69s 406ms/step - loss: 0.1264 - accuracy: 0.9568\n",
            "Epoch 16/50\n",
            "171/171 [==============================] - 67s 387ms/step - loss: 0.1352 - accuracy: 0.9527\n",
            "Epoch 17/50\n",
            "171/171 [==============================] - 67s 395ms/step - loss: 0.1200 - accuracy: 0.9584\n",
            "Epoch 18/50\n",
            "171/171 [==============================] - 68s 396ms/step - loss: 0.1473 - accuracy: 0.9469\n",
            "Epoch 19/50\n",
            "171/171 [==============================] - 68s 398ms/step - loss: 0.1093 - accuracy: 0.9629\n",
            "Epoch 20/50\n",
            "171/171 [==============================] - 67s 389ms/step - loss: 0.1166 - accuracy: 0.9602\n",
            "Epoch 21/50\n",
            "171/171 [==============================] - 67s 390ms/step - loss: 0.1259 - accuracy: 0.9613\n",
            "Epoch 22/50\n",
            "171/171 [==============================] - 79s 464ms/step - loss: 0.1012 - accuracy: 0.9668\n",
            "Epoch 23/50\n",
            "171/171 [==============================] - 90s 529ms/step - loss: 0.1165 - accuracy: 0.9623\n",
            "Epoch 24/50\n",
            "171/171 [==============================] - 82s 478ms/step - loss: 0.0798 - accuracy: 0.9711\n",
            "Epoch 25/50\n",
            "171/171 [==============================] - 68s 394ms/step - loss: 0.1015 - accuracy: 0.9688\n",
            "Epoch 26/50\n",
            "171/171 [==============================] - 66s 384ms/step - loss: 0.0756 - accuracy: 0.9734\n",
            "Epoch 27/50\n",
            "171/171 [==============================] - 67s 394ms/step - loss: 0.0836 - accuracy: 0.9691\n",
            "Epoch 28/50\n",
            "171/171 [==============================] - 70s 411ms/step - loss: 0.1089 - accuracy: 0.9631\n",
            "Epoch 29/50\n",
            "171/171 [==============================] - 65s 381ms/step - loss: 0.0780 - accuracy: 0.9731\n",
            "Epoch 30/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.0727 - accuracy: 0.9787\n",
            "Epoch 31/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.0704 - accuracy: 0.9775\n",
            "Epoch 32/50\n",
            "171/171 [==============================] - 70s 407ms/step - loss: 0.0800 - accuracy: 0.9731\n",
            "Epoch 33/50\n",
            "171/171 [==============================] - 65s 383ms/step - loss: 0.0751 - accuracy: 0.9744\n",
            "Epoch 34/50\n",
            "171/171 [==============================] - 67s 394ms/step - loss: 0.0659 - accuracy: 0.9791\n",
            "Epoch 35/50\n",
            "171/171 [==============================] - 69s 405ms/step - loss: 0.0789 - accuracy: 0.9717\n",
            "Epoch 36/50\n",
            "171/171 [==============================] - 67s 391ms/step - loss: 0.0576 - accuracy: 0.9832\n",
            "Epoch 37/50\n",
            "171/171 [==============================] - 67s 389ms/step - loss: 0.0726 - accuracy: 0.9758\n",
            "Epoch 38/50\n",
            "171/171 [==============================] - 65s 381ms/step - loss: 0.0777 - accuracy: 0.9750\n",
            "Epoch 39/50\n",
            "171/171 [==============================] - 71s 416ms/step - loss: 0.0741 - accuracy: 0.9781\n",
            "Epoch 40/50\n",
            "171/171 [==============================] - 66s 388ms/step - loss: 0.0821 - accuracy: 0.9727\n",
            "Epoch 41/50\n",
            "171/171 [==============================] - 68s 397ms/step - loss: 0.0475 - accuracy: 0.9857\n",
            "Epoch 42/50\n",
            "171/171 [==============================] - 67s 392ms/step - loss: 0.0723 - accuracy: 0.9756\n",
            "Epoch 43/50\n",
            "171/171 [==============================] - 66s 386ms/step - loss: 0.0845 - accuracy: 0.9723\n",
            "Epoch 44/50\n",
            "171/171 [==============================] - 68s 398ms/step - loss: 0.0567 - accuracy: 0.9818\n",
            "Epoch 45/50\n",
            "171/171 [==============================] - 67s 390ms/step - loss: 0.0526 - accuracy: 0.9816\n",
            "Epoch 46/50\n",
            "171/171 [==============================] - 68s 395ms/step - loss: 0.0531 - accuracy: 0.9813\n",
            "Epoch 47/50\n",
            "171/171 [==============================] - 73s 426ms/step - loss: 0.0519 - accuracy: 0.9836\n",
            "Epoch 48/50\n",
            "171/171 [==============================] - 70s 406ms/step - loss: 0.0626 - accuracy: 0.9799\n",
            "Epoch 49/50\n",
            "171/171 [==============================] - 73s 428ms/step - loss: 0.0575 - accuracy: 0.9822\n",
            "Epoch 50/50\n",
            "171/171 [==============================] - 73s 424ms/step - loss: 0.0593 - accuracy: 0.9801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7RAIvloTL03",
        "outputId": "a1cfba4d-23e3-432b-ebd6-e900b0482ee1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/trained_model2.h5\")"
      ],
      "metadata": {
        "id": "uj-eI4jbT2Ty"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2 test part\n",
        "#( test accuracy : 0.69)"
      ],
      "metadata": {
        "id": "Ymsvu0BULu4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to test data directory\n",
        "test_dir = os.path.join(inner_dir, 'test')\n",
        "\n",
        "# Check if the test directory exists\n",
        "if not os.path.exists(test_dir):\n",
        "    print(\"Test directory not found:\", test_dir)\n",
        "    exit()\n",
        "\n",
        "# Load test data (no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assuming images are organized in folders by class\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predict labels for test data\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tq6baBEU8wV",
        "outputId": "4b92faf5-dbda-4eda-f44c-1924989901cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1279 images belonging to 4 classes.\n",
            "43/43 [==============================] - 3s 58ms/step - loss: 1.6936 - accuracy: 0.6927\n",
            "Test Accuracy: 0.6927286982536316\n",
            "43/43 [==============================] - 2s 43ms/step\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    MildDemented       0.74      0.31      0.44       179\n",
            "ModerateDemented       0.88      0.58      0.70        12\n",
            "     NonDemented       0.90      0.66      0.76       640\n",
            "VeryMildDemented       0.55      0.89      0.68       448\n",
            "\n",
            "        accuracy                           0.69      1279\n",
            "       macro avg       0.77      0.61      0.65      1279\n",
            "    weighted avg       0.76      0.69      0.69      1279\n",
            "\n"
          ]
        }
      ]
    }
  ]
}